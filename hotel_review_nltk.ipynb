{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Impact, Charcoal, sans-serif; padding: 12px; font-size: 30px; color: #8b4513; text-align: center; line-height: 1.25;\">Sentiment Analysis<br><span style=\"color: #800000; font-size: 48px\"><b>TripAdvisor Hotel Reviews</b></span><br><span style=\"color: #a0522d; font-size: 20px\">Using Sklearn and Tensorflow</span></h1>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"assets/review.png\" alt=\"Hotel Review\" style=\"width:200px;\">\n",
    "</div>\n",
    "\n",
    "<p>Data source: <a href=\"https://www.kaggle.com/datasets/thedevastator/tripadvisor-hotel-reviews\">TripAdvisor Hotel Reviews</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">TABLE OF CONTENTS</span></b></h1>\n",
    "\n",
    "* [Importing Libraries](#1)\n",
    "* [Loading Dataset](#2)\n",
    "* [Text Preprocessing](#3)\n",
    "    * [Clean Text](#3.1)\n",
    "* [Data Visualization](#4)\n",
    "* [Building Model with Sklearn](#5)\n",
    "    * [Make Predictions](#5.1)\n",
    "    * [Prediction Interpretability using SHAP Values](#5.2)\n",
    "* [Building Model with Tensorflow](#6)\n",
    "* [Prediction](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Importing Libraries</span></b></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for array, linear algebra\n",
    "import pandas as pd # for data processing\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import string\n",
    "\n",
    "# Preprocessing and evaluation\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer # lemmatize a word\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet # large lexical database of English words\n",
    "from wordcloud import WordCloud # to visualize text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # converts a collection of raw documents into a matrix\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_scoreyy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import optuna\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Loading Dataset</span></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/trip_advisor_reviews.csv', encoding = 'ISO-8859-1')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 0.3, replace = False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This column is the same as index\n",
    "df = df.drop(['s.no.'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Text Preprocessing</span></b></h1>\n",
    "- For this dataset, we categorize all 5 and 4 stars reviews as a Good Review, the 3 start review as Neutral while all reviews from 2-star to 1-star, we categorize it as Bad Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(score):\n",
    "    if score >= 4:\n",
    "        return 'good'\n",
    "    elif score == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['rating'].apply(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chars(text):\n",
    "    return len(text)\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length'] = df['review'].apply(count_chars)\n",
    "df['words_count'] = df['review'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = df['review_length'].sum()\n",
    "print(f'Total words in the dataset before cleaning: {length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "<h1 style=\"font-family: Trebuchet MS; font-size: 20px; color: #b47238; text-align: left; \"><b>Clean up the text</b></h1>\n",
    "\n",
    "<ul>\n",
    "  <li>Remove 'empty' reviews and words with only 1 letter</li>\n",
    "  <li>Lowercase all text</li>\n",
    "  <li>Tokenize and split text into words</li>\n",
    "  <li>Remove stop words ('a', 'an', 'the', 'of', 'in', etc.)</li>\n",
    "  <li>Lemmatize the text: transform every word into its root form</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove \\t\n",
    "    text = text.replace('\\t', '')\n",
    "\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize sentence into words\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "\n",
    "        # Remove punctuation and words with numbers\n",
    "        words = [word.strip(string.punctuation) for word in words if not any(c.isdigit() for c in word)]\n",
    "\n",
    "        # Remove empty tokens and stopwords\n",
    "        words = [word for word in words if len(word) > 0 and word not in stopwords.words('english')]\n",
    "\n",
    "        # Lemmatize words\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word, 'v') for word in words]\n",
    "\n",
    "        cleaned_sentence = ' '.join(lemmatized_words)\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "\n",
    "    return ' '.join(cleaned_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_length = df['clean_review'].apply(len).sum()\n",
    "\n",
    "print(f'Total words in the dataset before cleaning: {length}')\n",
    "print(f'Total words in the dataset after cleaning: {new_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Data Visualization</span></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_proportions = df['rating'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "fig = px.bar(rating_proportions, x=rating_proportions.index, y=rating_proportions.values,\n",
    "             hover_data=[rating_proportions.values], color=rating_proportions.index,\n",
    "             height=400)\n",
    "\n",
    "# Configurar etiquetas y título del gráfico\n",
    "fig.update_layout(\n",
    "    xaxis_title='Rating',\n",
    "    yaxis_title='Proportion',\n",
    "    title={\n",
    "        'text': '<b>Hotel Review Rating Proportions</b>',\n",
    "        'font': {'size': 24, 'color': '#8b4513'},\n",
    "        'x': 0.5,  # Alineación centrada\n",
    "        'xanchor': 'center'  # Alineación centrada\n",
    "    },\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_coloraxis=None)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<strong>Ratings Breakdown:</strong><br>\n",
    "1 star: 7.03%<br>\n",
    "2 stars: 8.51%<br>\n",
    "3 stars: 10.49%<br>\n",
    "4 stars: 30.70%<br>\n",
    "5 stars: 43.27%\n",
    "</p>\n",
    "<p>\n",
    "The majority of TripAdvisor hotel reviews (43.27%) are rated with 5 stars, indicating a high level of satisfaction. Additionally, 4-star ratings hold a significant proportion (30.70%). Lower ratings (1 to 3 stars) represent a smaller proportion of the reviews.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.displot(data=df, x='review_length', hue='rating', palette='viridis', kind='kde', fill=True, aspect=2)\n",
    "\n",
    "plt.suptitle('Distribution of Review Length by Rating', fontweight='bold', fontsize=18, color='#8b4513')\n",
    "plot.set(xlabel='Total words', ylabel='Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def wordCloud_generator(data, color, color_map):\n",
    "    wave_mask = np.array(Image.open('assets/cloud.png'))\n",
    "    wordcloud = WordCloud(width=1000, height=1000,\n",
    "                          background_color=color,\n",
    "                          min_font_size=12,\n",
    "                          colormap=color_map,\n",
    "                          mask=wave_mask\n",
    "                          ).generate(' '.join(data['clean_review'].values))\n",
    "    \n",
    "    # plot the WordCloud image\n",
    "    plt.figure(figsize=(10, 10), facecolor=None)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good_neutral = df[df['score'].isin(['good', 'neutral'])][['clean_review']]\n",
    "df_bad = df[df['score'] == 'bad'][['clean_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud_generator(df_good_neutral, 'white', 'ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud_generator(df_bad, 'white', 'Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Building Model with Sklearn Classifiers Models</span></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_review']\n",
    "Y = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Calculate the proportion of values in each set\n",
    "train_proportions = y_train.value_counts() / len(y_train)\n",
    "test_proportions = y_test.value_counts() / len(y_test)\n",
    "\n",
    "print(\"Proportions in the training set:\")\n",
    "print(train_proportions)\n",
    "\n",
    "print(\"\\nProportions in the test set:\")\n",
    "print(test_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "class_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(\"Class Mapping:\", class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer()\n",
    "train_tfid_matrix = tfid.fit_transform(X_train)\n",
    "test_tfid_matrix = tfid.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tfid, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(random_state=42),\n",
    "          RandomForestClassifier(random_state=42),\n",
    "          XGBClassifier(random_state=42, objective='error'),\n",
    "          SVC(random_state=42),\n",
    "          LogisticRegression(random_state=42, max_iter=1000),\n",
    "          KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for model in models:\n",
    "    cross_val = cross_val_score(model, train_tfid_matrix, y_train_encoded, scoring='accuracy',\n",
    "                               cv=StratifiedKFold(10)).mean()\n",
    "    accuracy.append(cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = ['DecisionTreeClassifier', 'RandomForestClassifier', 'XGBClassifier', 'SVC',\n",
    "         'LogisticRegression', 'KNeighborsClassifier']\n",
    "\n",
    "\n",
    "acc = pd.DataFrame({'Model': models_name, 'Accuracy': accuracy})\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(random_state=42)\n",
    "best_model.fit(train_tfid_matrix, y_train_encoded)\n",
    "pred = best_model.predict(test_tfid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(random_state=42, **params)\n",
    "    model.fit(train_tfid_matrix, y_train_encoded)\n",
    "    \n",
    "    y_pred = model.predict(test_tfid_matrix)\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = XGBClassifier(random_state=42, **{f'xgb_{key}': value for key, value in best_params.items()})\n",
    "best_model.fit(train_tfid_matrix, y_train_encoded)\n",
    "\n",
    "pred = best_model.predict(test_tfid_matrix) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_test_encoded, pred)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "sns.heatmap(cf, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "\n",
    "probs = best_model.predict_proba(test_tfid_matrix)  # Get predicted probabilities\n",
    "\n",
    "# Plot gain curve\n",
    "skplt.metrics.plot_cumulative_gain(y_test, probs)\n",
    "plt.xlabel('Percentage of Samples')\n",
    "plt.ylabel('Gain')\n",
    "plt.title('Cumulative Gain Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cr = classification_report(y_test_encoded, pred)\n",
    "print(cr)\n",
    "cf = confusion_matrix(y_test_encoded, pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open('ml_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the model trained and the transformed values used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = pickle.load(open('ml_model.pkl','rb'))\n",
    "tfidf = pickle.load(open('tfidf.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_predict(text):\n",
    "    text = clean_text(text)\n",
    "    tfid_matrix = tfidf.transform([text])\n",
    "    pred_proba = ml.predict_proba(tfid_matrix)\n",
    "    idx = np.argmax(pred_proba)\n",
    "    pred = ml.classes_[idx]\n",
    "    \n",
    "    return pred, pred_proba[0][idx]\n",
    "\n",
    "ml_predict('poor room service')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(train_tfid_matrix)\n",
    "\n",
    "# Visualize the SHAP values\n",
    "shap.summary_plot(shap_values, train_tfid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], train_tfid_matrix[0], matplotlib=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Building Model with Tensorflow</span></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "tokenizer = Tokenizer(num_words=50000, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# print(tokenizer.word_index)\n",
    "total_word = len(tokenizer.word_index)\n",
    "print('Total distinct words: {}'.format(total_word))\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_seq)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_seq)\n",
    "\n",
    "# One hot encoding the label\n",
    "lb = LabelBinarizer()\n",
    "train_labels = lb.fit_transform(y_train)\n",
    "test_labels = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
    "pickle.dump(lb, open('label.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Embedding(total_word, 8),\n",
    "                                    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(64, kernel_regularizer=l2(0.001),\n",
    "                                                          bias_regularizer=l2(0.001), activation='relu'),\n",
    "                                    tf.keras.layers.Dense(3, activation='softmax')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_padded, train_labels, epochs=25, validation_data=(test_padded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics[['accuracy', 'val_accuracy']].plot()\n",
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dl_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1><b><span style=\"color: #8b4513; font-size: 28px\">Building Model with Tensorflow</span></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def ml_predict(text):\n",
    "    clean_text = clean_text(text)\n",
    "    tfid_matrix = tfid.transform([clean_text])\n",
    "    pred = best_model.predict(tfid_matrix)[0]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# Deep Neural Network\n",
    "def dl_predict(text):\n",
    "    clean_text = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([clean_text])\n",
    "    padded = pad_sequences(seq)\n",
    "\n",
    "    pred = model.predict(padded)\n",
    "    # Get the label name back\n",
    "    result = lb.inverse_transform(pred)[0]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Such a comfy place to stay with the loved one'\n",
    "\n",
    "print('Prediction using Logistic Regression: {}'.format(ml_predict(text)))\n",
    "print('Prediction using DNN: {}'.format(dl_predict(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'Awful room services and slow wifi connection'\n",
    "\n",
    "print('Prediction using XGBoost: {}'.format(ml_predict(text2)))\n",
    "print('Prediction using DNN: {}'.format(dl_predict(text2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = 'Hard to get here but the scenery is wonderful'\n",
    "\n",
    "print('Prediction using Logistic Regression: {}'.format(ml_predict(text3)))\n",
    "print('Prediction using DNN: {}'.format(dl_predict(text3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
